{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d4a7fee-ed79-40ca-b6dc-a40c667f7220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3229877a-c231-471b-b7ce-8dfd5ca048dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['font.sans-serif'] = ['Simhei']  #显示中文\n",
    "plt.rcParams['axes.unicode_minus'] = False "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "662588f2-9826-4435-8193-061a612714d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class logsitic_regression:\n",
    "    def __init__(self, xtrain,ytrain,xtest,ytest):\n",
    "        self.train_x = xtrain\n",
    "        self.train_y = ytrain\n",
    "        self.test_x = xtest\n",
    "        self.test_y = ytest\n",
    "    def best_parameters(self,penaltys,Cs):\n",
    "        tuned_parameters=dict(penalty = penaltys,C = Cs)\n",
    "        lr_penalty=LogisticRegression(solver='liblinear',random_state = 0)\n",
    "        grid = GridSearchCV(lr_penalty,tuned_parameters,cv=10,scoring='accuracy',n_jobs=4)\n",
    "        grid.fit(self.train_x,self.train_y)\n",
    "        print('best_score:',grid.best_score_)\n",
    "        print('best_params:',grid.best_params_)\n",
    "    def fitting(self,pena,C):\n",
    "        grid = LogisticRegression(penalty=pena,C = C,solver='liblinear',random_state = 0)\n",
    "        grid.fit(self.train_x,self.train_y)\n",
    "        self.coef = grid.coef_\n",
    "        self.score = grid.score(self.test_x,self.test_y)\n",
    "        print(\"the coefficient of variables:\\n\",grid.coef_)\n",
    "        print(\"the accuracy score on test:\",grid.score(self.test_x,self.test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8254c559-f86f-406b-b1b5-5674e7ab8699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.feature_extraction import  DictVectorizer\n",
    "from sklearn import tree\n",
    "import graphviz\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf7379a4-73dd-4069-ab22-6ceb63a1e9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class decision_tree:\n",
    "    def __init__(self, xtrain,ytrain,xtest,ytest,feature_name):\n",
    "        self.train_x = xtrain\n",
    "        self.train_y = ytrain\n",
    "        self.test_x = xtest\n",
    "        self.test_y = ytest\n",
    "        self.feature_name = feature_name\n",
    "    def fitting(self,max_depth=None,feature_importance_plotting=0):\n",
    "        dec = DecisionTreeClassifier(max_depth=max_depth,random_state=50)\n",
    "        dec.fit(self.train_x,self.train_y)\n",
    "        self.score = dec.score(self.test_x, self.test_y)\n",
    "        print(\"the accuracy score on test:\",dec.score(self.test_x, self.test_y))\n",
    "        #生成决策树图片\n",
    "        dot_data = export_graphviz(dec, out_file=None, feature_names=self.feature_name,class_names=['0','1'],filled=True,rounded=True)\n",
    "        graph = graphviz.Source(dot_data)\n",
    "        graph.render() \n",
    "        self.feature_importance=[*zip(self.feature_name,dec.feature_importances_)]\n",
    "\n",
    "        #特征重要性绘图\n",
    "        if feature_importance_plotting:\n",
    "            feature_names = list(self.feature_name)\n",
    "            feature_importances_df = pd.DataFrame({'feature': feature_names, 'importance': dec.feature_importances_})\n",
    "            feature_importances_df = feature_importances_df.sort_values('importance', ascending=False)\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, len(feature_names)))\n",
    "            fig, ax = plt.subplots(figsize=(16, 6))\n",
    "            ax.barh(feature_importances_df['feature'], feature_importances_df['importance'], color=colors)\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_xlabel('特征重要性', fontsize=12)\n",
    "            for i, v in enumerate(feature_importances_df['importance']):\n",
    "                ax.text(v + 0.01, i, str(round(v, 3)), va='center', fontname='Times New Roman', fontsize=8)\n",
    "            plt.show()\n",
    "            plt.savefig('决策树特征重要性.png')\n",
    "\n",
    "    #调参,限制树的最大深度，超过设定深度的树枝全部剪掉\n",
    "    def max_depth_finding(self,n):\n",
    "        test = []\n",
    "        for i in range(n):\n",
    "            dec = DecisionTreeClassifier(max_depth=i+1,random_state=50)\n",
    "            dec.fit(self.train_x,self.train_y)\n",
    "            score = dec.score(self.test_x, self.test_y)\n",
    "            test.append(score) \n",
    "        print(\"the best depth of the tree:\",test.index(max(test))+1)\n",
    "        print(\"the best score on test:\",max(test))\n",
    "        plt.plot(range(1,n+1),test,color=\"coral\",label=\"max_depth\")\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"max_depth\")\n",
    "        plt.ylabel(\"score\")\n",
    "        plt.savefig( 'max_depth.png')\n",
    "        plt.show()\n",
    "        \n",
    "    def score_with_depth_plotting(self):\n",
    "        tr = []\n",
    "        te = []\n",
    "        for i in range(10):\n",
    "            dec = DecisionTreeClassifier(random_state=50,max_depth=i+1)\n",
    "            dec.fit(self.train_x,self.train_y)\n",
    "            score_tr = dec.score(self.train_x,self.train_y)\n",
    "            score_te = dec.score(self.test_x, self.test_y)\n",
    "            tr.append(score_tr)\n",
    "            te.append(score_te)\n",
    "        plt.plot(range(1,11),tr,color=\"red\",label=\"train\")\n",
    "        plt.plot(range(1,11),te,color=\"blue\",label=\"test\")\n",
    "        plt.xticks(range(1,11))\n",
    "        plt.legend()\n",
    "        plt.xlabel(\"max_depth\")\n",
    "        plt.ylabel(\"score\")\n",
    "        plt.savefig('决策树_过拟合.png')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ed6a108-7a4c-4812-bee3-6c34aa402d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "class randomforest:\n",
    "    def __init__(self, xtrain,ytrain,xtest,ytest,feature_name,X,Y):\n",
    "        self.train_x = xtrain\n",
    "        self.train_y = ytrain\n",
    "        self.test_x = xtest\n",
    "        self.test_y = ytest\n",
    "        self.feature_name = feature_name\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "    def best_n_estimators(self,n):\n",
    "        superpa = []\n",
    "        for i in range(n):\n",
    "            rfc = RandomForestClassifier(n_estimators=i+1,n_jobs=-1,random_state=0)\n",
    "            rfc_s = cross_val_score(rfc,self.X,self.Y,cv=10).mean()\n",
    "            superpa.append(rfc_s)\n",
    "        print(\"the best n_estimators:\",superpa.index(max(superpa))+1)\n",
    "        print(\"the best score of cross_validation:\",max(superpa))\n",
    "        plt.figure(figsize=[20,5])\n",
    "        plt.plot(range(1,n+1),superpa)\n",
    "        plt.xlabel(\"n_estimators\")\n",
    "        plt.ylabel(\"score\")\n",
    "        plt.savefig('随机森林.png')\n",
    "        plt.show()\n",
    "    def fitting(self,n_estimators,feature_importance_plotting=1):\n",
    "        rfc = RandomForestClassifier(n_estimators=n_estimators,random_state=0) \n",
    "        rfc = rfc.fit(self.train_x,self.train_y)\n",
    "        self.score = rfc.score(self.test_x, self.test_y)\n",
    "        self.feature_importance=[*zip(self.feature_name,rfc.feature_importances_)]\n",
    "        print(\"the best score on test:\",rfc.score(self.test_x, self.test_y))\n",
    "\n",
    "        #特征重要性绘图\n",
    "        if feature_importance_plotting:\n",
    "            feature_names = list(self.feature_name)\n",
    "            feature_importances_df = pd.DataFrame({'feature': feature_names, 'importance': rfc.feature_importances_})\n",
    "            feature_importances_df = feature_importances_df.sort_values('importance', ascending=False)\n",
    "            colors = plt.cm.viridis(np.linspace(0, 1, len(feature_names)))\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            ax.barh(feature_importances_df['feature'], feature_importances_df['importance'], color=colors)\n",
    "            ax.invert_yaxis()\n",
    "            ax.set_xlabel('特征重要性', fontsize=12)\n",
    "            for i, v in enumerate(feature_importances_df['importance']):\n",
    "                ax.text(v + 0.01, i, str(round(v, 3)), va='center', fontname='Times New Roman', fontsize=8)\n",
    "            plt.show()\n",
    "            plt.savefig(\"随机森林特征重要性.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b0fd1ce-6185-482e-819b-f452c964ce68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook model_fitting.ipynb to python\n",
      "[NbConvertApp] Writing 7232 bytes to model_fitting.py\n"
     ]
    }
   ],
   "source": [
    "try:   \n",
    "    !jupyter nbconvert --to python model_fitting.ipynb\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8719633e-a236-448c-be73-bedeaa6e1b27",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
